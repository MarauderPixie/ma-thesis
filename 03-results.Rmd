---
chapter: 3
knit: "bookdown::render_book"
---

```{r ch3-models-and-bayes-factors, cache=TRUE, eval=FALSE}
# h1_null  <- readRDS("models/h1_transfer/h10.rds")
# h1_block <- readRDS("models/h1_transfer/h11.rds")
# h1_instr <- readRDS("models/h1_transfer/h12.rds")
# h1_both  <- readRDS("models/h1_transfer/h131.rds")
# h1_inter <- readRDS("models/h1_transfer/h132.rds")
```

# Results {#ch:results}

The following chapter lays out the results of the experiment and the analyses with respect to their given hypothesis. 


## H1: Extrapolations in Transfer Phase

The main interest of this study is to find out whether an increase in the number of XOR extrapolations and thereby the learning of a full XOR category structure is facilitated by the ordering of rules during learning (**H1.1**), the use of rule instructions (**H1.2**) and a possible interaction of both (**H1.3**). Resulting from the 2x2 factorial setup described under section \@ref(ch2-setup) there are two manipulated/independent variables with two levels each. Independent variable 1 are the rule instructions with levels 0 for neutral language and 1 for rule language. Independent variable 2 is the rule order with levels 0 for the mixed condition and 1 for the blocked condition. The dependent variable for hypotheses 1.1-1.3 is whether the chosen category for the nine critical transfer trials (see fig. \@ref(fig:ch2-stimuli)) has been extrapolated (1) or not (0). 

(ref:h1-tbl-summary) Mean proportion of extrapolated stimuli per person and proportion of extrapolators between experimental condition.

```{r h1-tbl-summary}
beobachtet <- extra_binom %>% 
  group_by(Group, rules, blocked) %>% 
  summarise(
    n = n(),
    mean_p = mean(p),
    sd_p   = sd(p),
    mean_ckab6 = mean(exab6),
    sum_ckab6  = sum(exab6),
    .groups = "drop"
  )

total_by_man <- extra_binom %>% 
  summarise(
    Group = "Total",
    n = n(),
    mean_p = mean(p),
    sd_p   = sd(p),
    mean_ckab6 = mean(exab6),
    sum_ckab6  = sum(exab6),
  )

beobachtet %>% 
    bind_rows(total_by_man) %>%
    transmute(
        Group = Group,
        "n" = n,
        "Extrapolators" = paste0(sum_ckab6, " (", 
                                 round(mean_ckab6 * 100), "%)"),
        "Mean" = paste0(round(mean_p * 100, 2), "%"),
        "SD"   = round(sd_p * 100, 2)
    ) %>% 
  # xtable(booktabs = TRUE, caption = "(ref:h1-tbl-summary)") %>%
  # xtable2kable() %>%
  kbl(booktabs = TRUE, align = "r", caption = "(ref:h1-tbl-summary)") %>%
  kable_styling(full_width = FALSE, font_size = 10,
                position = "center", latex_options = "hold_position") %>% # "float_right") %>% 
  add_header_above(c(" " = 3, "XOR Extrapolations" = 2)) %>%
  row_spec(4, hline_after = TRUE) %>% 
  row_spec(5, bold = TRUE)
```

@CK17 classified participants that extrapolated more than 5 of these stimuli as "extrapolators". The same is done here for comparison to their results - people _not_ extrapolating and therefore inferring category membership by proximity to the "neighboring" stimuli are here called "proximators". Table \@ref(tab:h1-tbl-summary) shows the final group sizes, the average percentage of extrapolated stimuli per person as well as the percentage of extrapolators between experimental conditions. Furthermore, figure \@ref(fig:h1-extrapolations) (A) shows the distributions of extrapolated stimuli per person between experimental groups and (B) shows decision gradients for all stimuli across the conditions for extrapolators and proximators. For an overview of individual responses see fig. \@ref(fig:apx-transfer) in the appendix.

(ref:h1-extrapolations) (A) Number of xor-extrapolated stimuli between experimental groups. (B) Decision gradients for each stimulus between groups and people extrapolating to a full XOR solution (Extrapolators) and people inferring group membership by similarity to neighboring categories (Proximators). Cave: _n_ = 1 for subgroup 'No Treatment - Extrapolators'.

```{r h1-extrapolations, fig.cap="(ref:h1-extrapolations)", fig.height=4}
ext_hist <- transfer %>% 
  filter(item == "transfer") %>% 
  group_by(subj_id, Group) %>% 
  summarise(ext = sum(extrapolation)) %>%
  ggplot(aes(ext)) +
    facet_wrap(~Group, nrow = 1, 
               labeller = label_wrap_gen(width=10)) +
    geom_histogram(binwidth = 1) +
    scale_x_continuous(breaks = scales::pretty_breaks(n = 10), 
                       labels = c("", 0:9, "")) +
    labs(x = "Extrapolations", y = "n") +
    theme(panel.grid.minor.x = element_blank(),
          panel.grid.major.x = element_blank(),
          panel.spacing = unit(5, "pt"))
          
ext_grad <- transfer %>% 
  left_join(proxy_ex_ids, by = c("subj_id", "Group")) %>% 
  count(Group, img_x, img_y, extrap, response) %>% 
  spread(response, n) %>% 
  mutate(
    Nobz = ifelse(is.na(Nobz), 0, Nobz),
    Grot = ifelse(is.na(Grot), 0, Grot),
    n = Nobz + Grot,
    p_Grot = (Grot / n * 100) |> round(2)
  ) %>% 
  ggplot(aes(img_x, img_y, fill = p_Grot)) +
    facet_grid(extrap~Group, 
               labeller = label_wrap_gen(width=10)) +
    geom_tile(size = .2, color = "white") +
    scale_fill_viridis_c() +
    theme_transfer +
    theme(legend.position = "none",
          panel.spacing = unit(5, "pt"),
          strip.text.x = element_blank())

ext_hist / ext_grad + 
  plot_layout(heights = c(1, 2)) +
  plot_annotation(tag_levels = 'A')
```

### H1.1: main effect of rule order

Hypothesis 1.1 predicts an increase in xor-extrapolations under the blocked rule condition. Two bayesian logistic models have been compared in order to quantify evidence for such an effect. For both models, the dependent variable is the number of xor-extrapolations. Model 1 includes no fixed effects, model 2 includes the blocked rule as a fixed effect; both models are fit with by-subject random intercepts to account for individual differences. Priors over the intercept parameters were set as $student\_t(df = 3, location = -1.4, scale = 1)$, which corresponds to an assumed 30% of the participants extrapolating at least 6 out ouf 9 trials, $student\_t(df = 3, location = 0.5, scale = 1)$ for the slope of the main effect, assuming an approximately 10% increase in extrapolations and $student\_t(df = 3, location = 2.2, scale = 1)$ with a lower bound of 0 and an upper bound of 5 for the random by-participant intercepts. The bayes factor of comparing model 2 to model 1 (blocked rule vs. no blocked rule) is `r h1_bfs[1,2]`, which amounts to moderate evidence in favor of Hypothesis 1.1: the delayed introduction of a context modulating stimulus indeed seems to make the rule inversion more likely to happen.

(ref:h1-tbl-bfs) Model comparison for effects of rule instruction, blocked rules and their interaction; Bayes Factors for $M_1$ over $M_2$ obtained via bridge sampling.

```{r h1-tbl-bfs}
h1_bfs %>% 
  kbl(booktabs = TRUE, escape = FALSE, 
      caption = "(ref:h1-tbl-bfs)", align = "l") %>% 
  kable_styling(full_width = TRUE) %>% 
  add_header_above(c(" ", "$M_2$" = 4), escape = FALSE) %>% 
  column_spec(1, width = "5cm")
```

### H1.2: main effect of rule instructions

Hypothesis 1.2 predicts an increase in xor-extrapolations under the rule instructions condition. Two bayesian logistic models have been compared in order to quantify evidence for such an effect. For both models, the dependent variable is the number of xor-extrapolations. Model 1 includes no fixed effects, model 2 includes the rule instructions as a fixed effect; both models are fit with by-subject random intercepts. Priors over parameters were set the same as for H1.1. The bayes factor of comparing model 2 to model 1 (rule vs. neutral instructions) is `r h1_bfs[2,2]`, which amounts to no meaningful evidence in favor of Hypothesis 1.2: it seems that being instructed to find a rule did not lead to a stronger learning and application of rule inversion.

Table: (\#tab:model-summary) Ugly and absolutely unformatted, incomplete and rather convoluted model summary table.

Parameter      Median          95% CI     Rhat      ESS               95% CI       Fit
-------------  ------  ---------------   -----  -------  -------------------  --------
(Intercept)     -5.67  [-7.13, -4.42]    1.001  9427.00       [-7.14, -4.40]          
blockedyes       1.48  [ 0.28,  2.88]    1.001  7064.00       [ 0.26,  2.86]          
rulesyes         0.75  [-0.40,  1.97]    1.001  8583.00       [-0.39,  1.97]          
ELPD                                                                           -316.67
LOOIC                                                                           633.34
WAIC                                                                            613.95
R2                                                                                0.66
Sigma                                                                             1.81
Log_loss                                                                          0.14

### H1.3: Interaction of blocked rules and instructions 

Hypothesis 1.3 predicts a possible interaction of the main effects of the blocked and rule instructions. Again, two bayesian logistic models have been compared in order to quantify evidence for such an effect. For both models, the dependent variable is the number of xor-extrapolations. Fixed effects are both main effects for model 1 with an interaction term added to model 2; both models are fit with by-subject random intercepts. Priors over parameters were again set identical to those under H1.1. The bayes factor of comparing model 2 to model 1 (interaction vs. no interaction) is `r h1_bfs[4,5]`, which amounts to no meaningful evidence in favor of Hypothesis 1.3: it seems to make no difference to be exposed to both effects over being exposed to only one of them.


## H2: Learning Accuracy with Rule Instructions

The second hypothesis concerns itself with the learning of a rule, namely a variant of the classic Type II rule otherwise known as exclusive-or problem. Figure \@ref(fig:h2-lcurves) shows the learning curves of the group being instructed to find a rule and the one with neutral task instructions.

To investigate the prediction of hypothesis 2 on a quicker learning of a type II rule structure, two bayesian logistic models have been comparedt. The dependent variable is the correct classification of traning stimuli, aggregated by training block and by participant. Model 1 again includes no fixed effects, whereas model 2 treats rule instructions as such; both models are fit with by-subject random intercepts with random slopes for the training blocks. The prior on the intercept  is $student\_t(df = 3, location = 2, scale = 1)$, assuming an average 88% learning accuracy, $student\_t(df = 3, location = 0, scale = 1)$ for the slope of the rule instructions condition, assuming no difference and $student\_t(df = 3, location = 2.2, scale = 1)$ with a lower bound of 0 and an upper bound of 5 for the random by-participant intercepts. Model comparison via bridge sampling yields no meaningful evidence for an effect of Rule Instructions ($BF_{21}$ = `r bf_h2`), such that hypothesis 2 can not be confirmed. The instructions mentioning rules does not facilitate the learning of rules.

(ref:h2-lcurves) Mean accuracy and 95% binomial confidence intervals for learning curves during training of groups with and without rule instructions.

```{r h2-lcurves, fig.cap="(ref:h2-lcurves)", out.width="90%", fig.height=3}
training %>%  
  filter(condition %in% c("control", "rules")) %>% 
  group_by(rules, block) %>% 
  summarise(
    n = n(),
    k = sum(correct),
    accuracy = mean(correct),
    acc_hi   = Hmisc::binconf(k, n, return.df = TRUE)$Upper,
    acc_lo   = Hmisc::binconf(k, n, return.df = TRUE)$Lower,
    .groups  = "drop"
  ) %>% 
  ggplot(aes(block, accuracy, fill = rules, color = rules, group = rules)) +
    geom_line(position = position_dodge(0.4)) +
    # geom_smooth(se = F, lty = "dotted", method = 'loess') +
    geom_point(position = position_dodge(0.4), size = 2.5, shape = 21, color = "white") +
    geom_linerange(aes(ymax = acc_hi, ymin = acc_lo),
                  position = position_dodge(0.4), size = .8) +
    labs(x = "Training Block", y = "Mean Accuracy",
        color = "Rule Instructions:", fill = "Rule Instructions:") +
    scale_color_manual(values = c("#4d4d4d", "#ac0634")) +
    scale_fill_manual(values = c("#4d4d4d", "#ac0634")) +
    scale_x_continuous(breaks = scales::pretty_breaks(n = 12)) +
    scale_y_continuous(labels = scales::label_percent()) +
    theme(legend.position = "top",
          panel.grid.minor.x = element_blank())
```

## Exploration

Sth Sth include ref to fig. \@ref(fig:xplore-prob)

(ref:xplore-prob) Average probability judement of any stimulus belonging to category Grot between experimental groups, subdivided by extrapolators and proximators. Cave: _n_ = 1 for subgroup 'No Treatment - Extrapolators'.

```{r xplore-prob, fig.cap="(ref:xplore-prob)", out.width="90%", fig.height=2.4}
transp <- stimprob %>%
  left_join(proxy_ex_ids, by = c("subj_id", "Group")) 

transp %>% 
  group_by(Group, extrap, img_x, img_y) %>% 
  summarise(
    p = mean(prob),
    .groups = "drop"
  ) %>%  
  ggplot(aes(img_x, img_y, fill = p)) +
    facet_grid(extrap ~ Group, switch = "y",
               labeller = label_wrap_gen(width=10)) +
    # facet_wrap(~Group, nrow = 1) ~
    geom_tile(size = .5, color = "white") +
    scale_fill_viridis_c() +
    labs(fill = "% Grot") +
    theme_transfer +
    theme(legend.position = "right",
          legend.text  = element_text(size = 6),
          strip.text   = element_text(size = 8),
          panel.spacing = unit(5, "pt"))
```

```{r auch-cool, fig.asp=1/1, caption="Pretty cool plot showing the distribution of probability judgements per stimulus that's sadly not all too informative", eval=FALSE}
transp %>%
  ggplot(aes(x = prob)) +
    facet_grid(cols = vars(img_x), 
               rows = vars(7 - img_y)) +
    geom_histogram(binwidth = 10) +
    theme(strip.text  = element_blank(),
          axis.text.y = element_blank(),
          axis.text.x = element_blank(),
          panel.spacing = unit(5, "pt"),
          axis.title.x  = element_blank(),
          axis.title.y  = element_blank(),
          panel.grid.minor   = element_blank(),
          panel.grid.major.x = element_blank(),
          panel.border = element_rect(color = "#3c3c3c", fill = NA))
```