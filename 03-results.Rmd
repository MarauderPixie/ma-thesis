---
chapter: 3
knit: "bookdown::render_book"
---

```{r ch3-models-and-bayes-factors, cache=TRUE}
# h1_null  <- readRDS("models/h1_transfer/h10.rds")
# h1_block <- readRDS("models/h1_transfer/h11.rds")
# h1_instr <- readRDS("models/h1_transfer/h12.rds")
# h1_both  <- readRDS("models/h1_transfer/h131.rds")
# h1_inter <- readRDS("models/h1_transfer/h132.rds")
```

# Results {#ch:results}

The following chapter lays out the results of the experiment and the analyses thereof. Beginning with a look at the descriptives we will deal with the hypotheses and close with some exploration. 

`[maybe something about model- and prior selection?]`


## Variables, indices and aggregation

auch: classification nach ck17

Resulting from the 2x2 factorial design described above there are two manipulated/independent variables with two levels each:

- **IV 1: Instructions** - explicitly introducting participants to look for rules and neutral language without any mentioning of rules
- **IV 2: Rule order** - blocked stimulus presentation and mixed stimulus presentation

The dependent variables are:

- **(training) Decision accuracy:** `0` or `1` - whether the presented stimulus has been correctly classified (aggregated successes _k_ of _n_ trials on subject and block level)
- **(transfer 1) Chosen category:** `Nobz` or `Grot` on the full set of stimuli; of special relevance to the research question are the nine stimuli not shown (and learned) during the training phase (see. fig. \@(ref:ch2-stimuli)), which are treated as either extrapolation (`1`) or proximation (`0`)
- **(transfer 2) Probability judgement:** `[0;100]` - integer depicting the numerical certainty of the presented stimulus belonging to either one Category.



## H1: Extrapolations in Transfer Phase

(ref:h1-tbl-summary) Mean proportion of extrapolated stimuli per person and proportion of extrapolators between experimental conditions.

```{r h1-tbl-summary}
beobachtet <- extra_binom %>% 
  group_by(Group, rules, blocked) %>% 
  summarise(
    n = n(),
    mean_p = mean(p),
    sd_p   = sd(p),
    mean_k = mean(k),
    sd_k   = sd(k),
    mean_ckab6 = mean(exab6),
    mean_ckab5 = mean(exab5),
    sum_ckab6  = sum(exab6),
    .groups = "drop"
  )

beobachtet %>% 
    transmute(
        Group = Group,
        "n" = n,
        "Extrapolators" = paste0(sum_ckab6, " (", 
                                 round(mean_ckab6 * 100), "%)"),
        "Mean" = paste0(round(mean_p * 100, 2), "%"),
        "SD"   = round(sd_p * 100, 2)
    ) %>% 
  # xtable(booktabs = TRUE, caption = "(ref:h1-tbl-summary)") %>%
  # xtable2kable() %>%
  kbl(booktabs = TRUE, align = "r", caption = "(ref:h1-tbl-summary)") %>%
  kable_styling(full_width = FALSE, font_size = 10,
                position = "center", latex_options = "hold_position") %>% # "float_right") %>% 
  add_header_above(c(" " = 3, "XOR Extrapolations" = 2))
```

The main interest of this study is to find out whether an increase in the number of XOR extrapolations and thereby the learning of a full XOR category structure is facilitated by the use of rule instructions, the ordering of rules during learning and a possible interaction of both. Table \@ref(tab:h1-tbl-summary) shows the final group sizes, the average percentage of extrapolated stimuli per person as well as the percentage of extrapolators - people who extrapolated at least 6 of the nine critical stimuli - between experimental conditions. Figure \@ref(fig:h1-extrapolations) (A) shows the number of extrapolations per person between experimental groups and (B) shows decision gradients for all stimuli across the conditions for extrapolators and proximators.^[see fig. \@ref(fig:apx-transfer) in the appendix for an overview of responses by every individual.].

(ref:h1-extrapolations) (A) Number of xor-extrapolated stimuli between experimental groups. (B) Decision gradients for each stimulus between groups and people extrapolating to a full XOR solution (Extrapolators) and people inferring group membership by similarity to neighboring categories (Proximators). Cave: _n_ = 1 for subgroup 'No Treatment - Extrapolators'.

```{r h1-extrapolations, fig.cap="(ref:h1-extrapolations)", fig.height=4}
ext_hist <- transfer %>% 
  filter(item == "transfer") %>% 
  group_by(subj_id, Group) %>% 
  summarise(ext = sum(extrapolation)) %>%
  ggplot(aes(ext)) +
    facet_wrap(~Group, nrow = 1, 
               labeller = label_wrap_gen(width=10)) +
    geom_histogram(binwidth = 1) +
    scale_x_continuous(breaks = scales::pretty_breaks(n = 10), 
                       labels = c("", 0:9, "")) +
    labs(x = "Extrapolations", y = "n") +
    theme(panel.grid.minor.x = element_blank(),
          panel.grid.major.x = element_blank(),
          panel.spacing = unit(5, "pt"))
          
ext_grad <- transfer %>% 
  left_join(proxy_ex_ids, by = c("subj_id", "Group")) %>% 
  count(Group, img_x, img_y, extrap, response) %>% 
  spread(response, n) %>% 
  mutate(
    Nobz = ifelse(is.na(Nobz), 0, Nobz),
    Grot = ifelse(is.na(Grot), 0, Grot),
    n = Nobz + Grot,
    p_Grot = (Grot / n * 100) |> round(2)
  ) %>% 
  ggplot(aes(img_x, img_y, fill = p_Grot)) +
    facet_grid(extrap~Group, 
               labeller = label_wrap_gen(width=10)) +
    geom_tile(size = .2, color = "white") +
    scale_fill_viridis_c() +
    theme_transfer +
    theme(legend.position = "none",
          panel.spacing = unit(5, "pt"),
          strip.text.x = element_blank())

ext_hist / ext_grad + 
  plot_layout(heights = c(1, 2)) +
  plot_annotation(tag_levels = 'A')
```

In order to quantify evidence for an effect of rule instructions and rule order, we fitted several Bayesian logistic models (estimated using MCMC sampling with 4 chains of 12000 iterations and a warmup of 2000) to predict the extrapolation of stimulus responses. Priors over parameters for all models were set as:

- $student\_t(df = 3, location = -1.4, scale = 1)$ for the intercept, assuming about 30% of the participants extrapolating at least 6 out ouf 9 trials as reported by @CK17
- $student\_t(df = 3, location = 0.5, scale = 1)$ for all slopes, assuming an approximately 10% increase in extrapolations in any group over the one receiving no treatment.
- $student\_t(df = 3, location = 2.2, scale = 1)$ with a lower bound of 0 and an upper bound of 5 for random intercepts per participant

The final model was fit with fixed effects for the blocked rule condition, the rule instructions condition and their interaction, as well as random intercepts per participant. Convergence and stability of the Bayesian sampling has been assessed using R-hat, which should be below 1.01 [@Vehtari2021], and Effective Sample Size (ESS), which should be greater than 1000 [@Buerkner2017], which in turn can be confirmed for all parameters of all models. Bayes Factors for all model comparisons were obtained by comparing marginal likelihoods via bridge sampling and are shown in table \@ref(tab:h1-tbl-bfs).
Compared to the intercept only model, we found moderate evidence (_BF_ = `r h1_bfs[1,2]`) in favour of the Blockd Rule model; no evidence (_BF_ = `r h1_bfs[2,2]`) against the Rule Instructions model (the least supported model); moderate evidence (_BF_ = `r h1_bfs[3,2]`) in favour of the model including both terms (the most supported model) and moderate evidence (_BF_ = `r h1_bfs[4,2]`) in favour of the model including both terms and their interaction. Since the model including both terms but no interaction is the most supported one, with an substantial explanatory power of $R^2 = 0.67$ (_CI_ = [0.64, 0.69]), that models posterior estimates are reported in table \@ref(tab:model-summary). As recommended by @VanDoorn2021, robustness of the acquired bayes factor of that model has further been established by running the same analyses with different sensible prior assumptions. The qualitative conclusions within the ranges declared under section \@ref(02-ic) stay largely the same even under different prior assumptions, for details see \@ref(bfrc) in the appendix.

(ref:h1-tbl-bfs) Model comparison for effects of rule instruction, blocked rules and their interaction; Bayes Factors for $M_1$ over $M_2$ obtained via bridge sampling.

```{r h1-tbl-bfs}
h1_bfs %>% 
  kbl(booktabs = TRUE, escape = FALSE, 
      caption = "(ref:h1-tbl-bfs)", align = "l") %>% 
  kable_styling(full_width = TRUE) %>% 
  add_header_above(c(" ", "$M_2$" = 4), escape = FALSE) %>% 
  column_spec(1, width = "5cm")
```

Table: (\#tab:model-summary) Ugly and absolutely unformatted, incomplete and rather convoluted model summary table.

Parameter      Median          95% CI     Rhat      ESS               95% CI       Fit
-------------  ------  ---------------   -----  -------  -------------------  --------
(Intercept)     -5.67  [-7.13, -4.42]    1.001  9427.00       [-7.14, -4.40]          
blockedyes       1.48  [ 0.28,  2.88]    1.001  7064.00       [ 0.26,  2.86]          
rulesyes         0.75  [-0.40,  1.97]    1.001  8583.00       [-0.39,  1.97]          
ELPD                                                                           -316.67
LOOIC                                                                           633.34
WAIC                                                                            613.95
R2                                                                                0.66
Sigma                                                                             1.81
Log_loss                                                                          0.14


## H2: Learning Accuracy with Rule Instructions

A similar approach as under Section 1.1 was taken to investigate a possible advantageous effect of instructions mentioning rules on learning the category structure. Two Bayesian 
logistic mixed models were fitted (estimated using MCMC sampling with 4 chains of 12000 iterations and a warmup of 2000) to predict correct classification of training stimuli. Priors over parameters were set as:

- $student\_t(df = 3, location = 2, scale = 1)$ for the intercept, assuming an average 88% learning accuracy
- $student\_t(df = 3, location = 0, scale = 1)$ for the slope of the rule instructions condition, assuming no difference.
- $student\_t(df = 3, location = 2.2, scale = 1)$ with a lower bound of 0 and an upper bound of 5 for all random effects

Model $M_1$ (intercept-only) assumes random intercepts for participants with a by-participant random effect for training blocks. Model $M_2$ assumes the same but adds the rule instructions condition as a fixed effect. Convergence and stability of the Bayesian sampling has again been assessed using R-hat and Effective Sample Size (ESS), which again can be confirmed for all parameters. Model comparison via bridge sampling yields no meaningful evidence for an effect of Rule Instructions ($BF_{21}$ = `r bf_h2`), even though the rule instructions model has substantial explanatory power ($R^2$ = 0.48, _CI_ = [0.43, 0.53]) and the rule effect has a 98.22% probability of being positive (_Median_ = 0.40, _95% HDI_= [0.03, 0.77]). 

(ref:h2-lcurves) Mean accuracy and 95% confidence intervals for learning curves during training of groups with and without rule instructions.

```{r h2-lcurves, fig.cap="(ref:h2-lcurves)", out.width="90%", fig.height=3}
training %>%  
  filter(condition %in% c("control", "rules")) %>% 
  group_by(rules, block) %>% 
  summarise(
    n = n(),
    k = sum(correct),
    accuracy = mean(correct),
    acc_hi   = Hmisc::binconf(k, n, return.df = TRUE)$Upper,
    acc_lo   = Hmisc::binconf(k, n, return.df = TRUE)$Lower,
    .groups  = "drop"
  ) %>% 
  ggplot(aes(block, accuracy, fill = rules, color = rules, group = rules)) +
    geom_line(position = position_dodge(0.4)) +
    # geom_smooth(se = F, lty = "dotted", method = 'loess') +
    geom_point(position = position_dodge(0.4), size = 2.5, shape = 21, color = "white") +
    geom_linerange(aes(ymax = acc_hi, ymin = acc_lo),
                  position = position_dodge(0.4), size = .8) +
    labs(x = "Training Block", y = "Mean Accuracy",
        color = "Rule Instructions:", fill = "Rule Instructions:") +
    scale_color_manual(values = c("#4d4d4d", "#ac0634")) +
    scale_fill_manual(values = c("#4d4d4d", "#ac0634")) +
    scale_x_continuous(breaks = scales::pretty_breaks(n = 12)) +
    scale_y_continuous(labels = scales::label_percent()) +
    theme(legend.position = "top",
          panel.grid.minor.x = element_blank())
```

## Exploration

Sth Sth include ref to fig. \@ref(fig:xplore-prob)

(ref:xplore-prob) Average probability judement of any stimulus belonging to category Grot between experimental groups, subdivided by extrapolators and proximators. Cave: _n_ = 1 for subgroup 'No Treatment - Extrapolators'.

```{r xplore-prob, fig.cap="(ref:xplore-prob)", out.width="90%", fig.height=2.4}
transp <- stimprob %>%
  left_join(proxy_ex_ids, by = c("subj_id", "Group")) 

transp %>% 
  group_by(Group, extrap, img_x, img_y) %>% 
  summarise(
    p = mean(prob),
    .groups = "drop"
  ) %>%  
  ggplot(aes(img_x, img_y, fill = p)) +
    facet_grid(extrap ~ Group, switch = "y",
               labeller = label_wrap_gen(width=10)) +
    # facet_wrap(~Group, nrow = 1) ~
    geom_tile(size = .5, color = "white") +
    scale_fill_viridis_c() +
    labs(fill = "% Grot") +
    theme_transfer +
    theme(legend.position = "right",
          legend.text  = element_text(size = 6),
          strip.text   = element_text(size = 8),
          panel.spacing = unit(5, "pt"))
```

```{r auch-cool, fig.asp=1/1, caption="Pretty cool plot showing the distribution of probability judgements per stimulus that's sadly not all too informative", eval=FALSE}
transp %>%
  ggplot(aes(x = prob)) +
    facet_grid(cols = vars(img_x), 
               rows = vars(7 - img_y)) +
    geom_histogram(binwidth = 10) +
    theme(strip.text  = element_blank(),
          axis.text.y = element_blank(),
          axis.text.x = element_blank(),
          panel.spacing = unit(5, "pt"),
          axis.title.x  = element_blank(),
          axis.title.y  = element_blank(),
          panel.grid.minor   = element_blank(),
          panel.grid.major.x = element_blank(),
          panel.border = element_rect(color = "#3c3c3c", fill = NA))
```