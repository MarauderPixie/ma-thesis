---
chapter: 2
knit: "bookdown::render_book"
---

```{r init_data}
exctest <- training %>% 
  filter(block > 9) %>% 
  group_by(subj_id) %>% 
  summarise(
    n = n(),
    k = sum(correct),
    p = k / n
  ) %>% 
  filter(p < .7)

demo <- demo %>% 
  filter(!(subj_id %in% exctest$subj_id))
training <- training %>% 
  filter(!(subj_id %in% exctest$subj_id))
transfer <- transfer %>% 
  filter(!(subj_id %in% exctest$subj_id))
stimprob <- stimprob %>% 
  filter(!(subj_id %in% exctest$subj_id))

dur <- quantile(demo$duration, c(.025, .95)) |> as.numeric()
```

# Methods {#ch:methods}

An online experiment has been conducted using the \_magpie 3 framework (source). This chapter describes the the collected sample, the experimental setup and procedure, the data preparation and the statistical models to be used for data analysis.

The experiment and indeed this thesis as a whole has been pre-registered according to the guidelines of the Open Science Foundation (source). Said pre-registration can be found here: [https://osf.io/wegm9](https://osf.io/wegm9)  
All code regarding the experiment and the data analysis can be found on the corresponding project page: [https://osf.io/gup7x/](https://osf.io/gup7x/)

## Data collection procedure and sample description

For data collection, the mailing lists of the psychology and cognitive science courses of the University of Osnabrück, as well as the psychology mailing list of the University of Bremen have been used, additional to several social media channels like facebook groups for psychology students and verbal recruitment. Participation was completely anonymous, voluntary and could be withdrawn at any time before submitting results. Students of said courses had the opportunity to receive 0.5 participation hours as compensation^[In order to keep the experimental data anonymous, the necessary personal data needed to hand out VP-hours was collected in a seperate dataset which could not be tracdd back to the experimental dataset. For the same reason, participation could not be revoked after data has been submitted.] and participants were required to be at least 18 years old and native german speakers. 

As of writing this thesis, a total of `r nrow(demo) + nrow(exctest)` participants took part in the experiment. Applying the exclusion criteria from the pre-registration leaves `r nrow(demo)`. On average, participants are `r mean(demo$age, na.rm = TRUE) |> round(1)` years old (_min_ = `r min(demo$age, na.rm = TRUE)`, _max_ = `r max(demo$age, na.rm = TRUE)`, _SD_ = `r sd(demo$age, na.rm = TRUE) |> round(2)`). Median duration of participation is `r median(demo$duration, na.rm = TRUE) |> round()` seconds. There are `r demo %>% filter(duration > dur[2]) %>% nrow()` participants whose participation took more than 30 minutes (>95% quantile); without these, standard deviation is `r demo %>% filter(duration < dur[2]) %>% pull(duration) %>% sd() |> round()` seconds.^[It's assumed they didn't actually take that long but rather opened the link in their browser and only returned to the experiment after a while or something like that]


## Experimental setup & procedure

The basic experimental setup is an iteration of the incomplete-XOR task by @CK17, using the same set of stimuli (see fig X) and consisting of a training and a transfer phase. In the training phase of the experiment, participants will be shown 6 squares of differing shade and size (see fig X) in a trial-and-feedback procedure. Upon presentation, they have to predict whether the stimulus belongs to A or B. After making their choice, they will receive feedback on whether it was correct. The stimuli of the reduced category (marked ‘A’ in fig. X) get displayed twice per block to "equate for category frequency" (Conaway & Kurtz, 2016), resulting in 8 trials per block across all conditions; that is, the four stimuli in the first 2 blocks / 16 trials of the blocked condition will also be shown twice per block. The training phase consists of 12 randomized blocks and therefore 96 trials in total.

In a subsequent transfer phase, the full set of 49 stimuli has to be classified without feedback.

The transfer phase will be repeated, the second time though participants are instructed to make a probability judgement about the stimulus category membership (e.g. 30% A, 70% B) via a slider rating ranging from 0 to 100 in steps by 1.

At the end of the experiment, pariticipants are asked to fill out demographic information as well as a question about their strategy during transfer, all of which are voluntarily given / can be left blank.

In addition to @CK17 there are four different experimental groups:

1. a control condition, where participants neither encounter instructions mentioning rules nor a simple rule at the beginning
2. a rule instructions condition, where participants are explicitly told to look for a rule to classify stimuli
3. a training order condition, where participants first learn a simple rule before they have to learn a more complex one
4. a combination of 2 and 3; participants get told to look for a rule and also learn a simple rule before the more complex one

This resulsts in a between subjects design with 2 factors - instructions (rule vs. neutral) and training order (blocked vs. mixed):

1. Instructions: with vs. without the mentioning of rules  
2. Training order:
    - **Blocked:** the first two blocks of training (16 trials) consist of a 'simple rule first' (stimuli that can be differentiated along one axis (either size or shape)), thereafter stimulus presentation identical to ‘mixed’ training
    - **Mixed:** all incomplete-xor trials at random from the beginning (mixed; in blocks of 8 trials) - see figure 1


<!-- ## Experimental Procedure

`idk man, it's basically the above, but maybe I should split setup & procedure?` -->


### Randomization

Participants will be randomly assigned to experimental groups by _magpie3's balanced randomization functionality.

For the training phase, the assignment of categories (which set of stimuli is A and which is B) will be randomized as well as the relevant dimension (size / shade) of the ‘simple rule’ trials of the blocked rule condition. Trial randomization will happen on a by-block level. For the transfer phases, randomization takes place blockwise on the full set of stimuli as a whole.

## Data preparation

In the preregistration the aimed for sample size is 40 complete and eligible observations per experimental group, resulting in a total of 160 participations. Since the analysis is rather complex in addition to being conducted with bayesian modeling, a power analysis in the classical sense is not applicable. For one, there is no way to actaully apply a plower analysis to a log-linear mixed effect model and for the other the intended use of such an analysis - being sure to not exceed a certain beta error rate given a desired effect size and alpha level - doesn't make any sense here; there simply are no such things as a Type I or II error in bayesian data analysis. Nonetheless, the practicality to estimate a desired effect size beforehand is still undisputable; after all, one still wants to be as certain as possible in their results - or, analoguos to the concept of statistical power, certain enough to draw proper conclusions. A naive power calculation for logistic regression then, assuming an odds ratio of 2, requires 34 people per group to reach a power of 80%. @Chen2010 show that this assumption translates to a rather small effect, with an OR of 1.68 being equivalent to a Cohen‘s d of 0.2. Simulations by @Chen2017 show similar results and @Brysbaert2018 also recommend a sample size of about 40 people (with eually as many stimuli), albeit on a more general basis.

### Variables, indices and aggregation

Resulting from the 2x2 factorial design there are two manipulated/independent variables with two levels each:

- **IV 1: Instructions** - explicitly introducting participants to look for rules and neutral language without any mentioning of rules  
- **IV 2: Rule order** - blocked stimulus presentation and mixed stimulus presentation

The dependent variables are:

- **(training) Decision accuracy:** `0` or `1` - whether the presented stimulus has been correctly classified (aggregated counts _k_ of _n_ on subject and block level)
- **(transfer 1) Chosen category:** `Nobz` or `Grot` on the full set of stimuli; of special relevance to the research question are the nine stimuli not shown (and learned) during the training phase (see. fig X)
- **(transfer 2) Probability judgement:** `[0;100]` - integer depicting the numerical certainty (see the discussion on that) of the presented stimulus belonging to either one category
- **(all) Response time:** in milliseconds from stimulus presentation to decision marked by clicking either category button

### Data exclusion

Participants that appear to be guessing in the training phase (the probability of correct classification on a single trial being 0.5) will be excluded. The above-chance number of correct classifications needed (based on a 5% alpha level) in the last 3 training blocks (24 trials) then is 16.

Additionally, should participants answer the question about any reason to not use their data in the affirmative, those participants will be excluded as well.


## Analysis plan

All analyses will be conducted using R (@R4, `r paste0(R.Version()$major, ".", R.Version()$minor, " - ", R.Version()$nickname)`). For a full list of all additionally used packages see Appendix X. All raw and prepared data as well as the corresponding R Scripts are available publicly on github.com; see Appendix X. 

To investigate the hypotheses laid out in the previous chapter, several mixed-effect logistic regression models using logit-links will be computed. Since the reasonably maximal random effect structure justified by the experimental setup (see @Barr2013) is not known a-priori, model complexity will be reduced to a maximal RE structure justified by the data (see @Bates2016) following these steps:

- fit model with max. RE structure
- identify posterior parameter estimates that do not conclusively differ from 0
- perform hierarchical Likelihood-Ratio-Tests

Futhermore, all models will use weakly informative priors. @Gelman2020 recommends $\operatorname{student}(df, mean = 0, sd = 1)$ where $3 \leq df \leq 7$, since the often used Cauchy-Distribution (that is, $\operatorname{student}(1, 0, 2.5)$) has too thick tails and a strict Gaussian might be too informative in the case at hand. Finally, Bayes Factors for model comparisons will be obtained via bridge sampling [@Gronau2020]. To obtain as robust BFs as possible, each model will have 4 MCMC chains with 12000 samples and 2000 warm-up samples each, resulting in 40000 posterior samples drawn per model [for details, see @Schad2021].

**Hypotheses 1** -- The dependent variable is the number of extrapolations of the nine untrained/incomplete stimuli (_k_ extrapolations of _n_ = 9 stimuli); independent variable is the experimental group assignment (instructions yes/no, blocked yes/no) Model comparisons for testint the hypotheses are therefore:

- **H1.1:** $M_{instructions} > M_{null}$
- **H1.2:** $M_{\text{rule order}} > M_{null}$
- **H1.3:** $M_{\text{instructions : rule order}} \approx M_{instructions} \approx M_{\text{rule order}} > M_{null}$

**Hypotheses 2** -- Depedent variable is the blockwise categorisation accuracy of the stimuli in the training phase, independent variable again is group assignment (instructions only) as well as the training block. Model comparsisons are therefore:

- **H2.1:** $M_{instructions} > M_{null}$
- **H2.2:** $M_{\text{instructions : block}} > M_{instructions} > M_{null}$



### Inference criteria

Hypotheses will be evaluated with Bayes Factors according to @Andras2014^[adjusted from Jeffreys, 1961 -- better double check that!], that is: $BF > 3$ costitutes moderate evidence for model A over model B (or vice versa when $BF < 1/3$) and $BF > 10$ (or $BF < 1/10$) will be interpreted as strong evidence respectively.


### Divergence from and additions to the pre-registration