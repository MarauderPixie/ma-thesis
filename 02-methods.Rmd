---
chapter: 2
knit: "bookdown::render_book"
---

```{r demo_data}
dur <- quantile(demo$duration, c(.025, .95)) |> as.numeric()
exc_id <- unique(exclud_trans$subj_id)
```

# Methods {#ch:methods}

An online experiment has been conducted using the \_magpie 3 framework (https://magpie-ea.github.io/magpie-site/). This chapter describes the collected sample, the experimental setup and procedure, the data preparation and the statistical methods to be used for data analysis. The experiment has been pre-registered according to the guidelines of the Open Science Foundation (https://osf.io/)^[Link to the pre-registration: [https://osf.io/wegm9](https://osf.io/wegm9)]. All code regarding the experiment and the data analysis can be found on the corresponding project page^[Link to the project: [https://osf.io/gup7x/](https://osf.io/gup7x/)].

## Data collection procedure and sample description

For data collection, the mailing lists of the psychology and cognitive science courses of the University of Osnabrück, as well as the psychology mailing list of the University of Bremen have been used, additional to several social media channels like facebook groups for psychology students and verbal recruitment. Participation was completely anonymous, voluntary and could be withdrawn at any time before submitting results. Students of said courses had the opportunity to receive 0.5 participation hours as compensation^[In order to keep the experimental data anonymous, the necessary personal data needed to hand out VP-hours was collected in a seperate dataset which could not be traced back to the experimental dataset. For the same reason, participation could not be revoked after data has been submitted.] and participants were required to be at least 18 years old and native german speakers. 

A total of `r nrow(demo) + length(exc_id)` participants took part in the experiment, of which `r nrow(demo)` are eligible after exclusion. Average age of participants is `r mean(demo$age, na.rm = TRUE) |> round(1)` years (_min_ = `r min(demo$age, na.rm = TRUE)`, _max_ = `r max(demo$age, na.rm = TRUE)`, _SD_ = `r sd(demo$age, na.rm = TRUE) |> round(2)`) and median duration of participation is `r median(demo$duration, na.rm = TRUE) |> round()` seconds. There are `r demo %>% filter(duration > dur[2]) %>% nrow()` participants whose participation took more than 30 minutes (>95% quantile); without these, standard deviation is `r demo %>% filter(duration < dur[2]) %>% pull(duration) %>% sd() |> round()` seconds.


## Experimental setup & procedure

The basic experimental setup is an iteration of the incomplete-XOR task by @CK17, using the same set of stimuli (see figure \@ref(fig:ch2-stimuli)) and consisting of a training and a transfer phase. In the training phase of the experiment, participants will be shown 6 squares of differing shade and size in a trial-and-feedback procedure. Upon presentation, they have to predict whether the given stimulus belongs to fictionally labeled categories "Nobz" or "Grot". After making their choice, participants will receive feedback on whether they were correct. The stimuli of the incomplete category get displayed twice per block to "equate for category frequency" [@CK17], resulting in 8 trials per block across all conditions; that is, all stimuli in the first 2 blocks / 16 trials of the blocked condition will also be shown twice per block. The training phase consists of 12 randomized blocks and therefore 96 trials in total.

(ref:ch2-stimuli) (A) Full set of stimuli to be used during the transfer phases, taken from @CK17. During the experiment, only one square was shown at a time. (B) Subset of stimuli used during training and unobserved subset of interest for extrapolation (marked X).

```{r ch2-stimuli, fig.show="hold", out.height="30%", out.width="100%", fig.cap="(ref:ch2-stimuli)"}
# knitr::include_graphics(c("figures/all-stimuli-arranged.png", 
#                           "figures/stimuli-trainfer.png"))
knitr::include_graphics("figures/stimulus-grids.png")
```

In a subsequent transfer phase, the full set of 49 stimuli has to be classified without feedback, but otherwise remains the same. After that, the transfer phase will be repeated, the second time though participants are instructed to make a probability judgement about the stimulus category membership (e.g. 30% Nobz, 70% Grot) via a slider rating ranging from 0 to 100 in steps by 1.

At the end of the experiment, pariticipants are asked to fill out basic demographic information as well as to answer a question about their strategy during transfer, all of which are voluntarily given and can be left blank. 

### Experimental manipulation

In addition to the basic setup of @CK17 there are four different experimental groups:

1. a control condition, where participants neither encounter instructions mentioning rules nor a simple rule at the beginning
2. a rule instructions condition, where participants are explicitly told to look for a rule to classify stimuli
3. a training order condition, where participants first learn a simple rule before they have to learn a more complex one
4. a combination of 2 and 3; participants are told to look for a rule and also learn a simple rule before the more complex one

This results in a between subjects design with 2 factors - instructions (rule vs. neutral) and training order (blocked vs. mixed). In more detail, the differences are:

1. Instructions:^[although the study was conducted in German, the translation is rather direct; see Appendix x for the full instructions.] 
    - **without mentioning rules:** "[You'll be shown] geometric shapes that differ in color and size. Your task is to learn, whether a figure belongs to category **Nobz** or category **Grot** [...] Do your best to master the categories Nobz and Grot!"
    - **mentioning rules:** "Your task is to learn a rule on the basis of color and size by which you can decide whether a figure belongs to category **Nobz** or category **Grot** [...] Do your best to master the rule for categories Nobz and Grot!"
2. Training order:
    - **Blocked:** the first two blocks of training (16 trials) consist of a 'simple rule first' - stimuli that can be differentiated along one axis (either size or shape) - and thereafter stimulus presentation is identical to the ‘mixed’ training
    - **Mixed:** all training trials - that is, the more complicated category structure - at random from the beginning (in blocks of 8 trials)

<!-- ## Experimental Procedure
`idk man, it's basically the above, but maybe I should split setup & procedure?` -->

### Randomization

Participants are randomly assigned to experimental groups by _magpie3's balanced randomization functionality upon opening the link to the experiment. For the training phase, the assignment of categories (which set of stimuli corresponds to Nobz and which to Grot) is randomized as well as the relevant dimension (size / shade) of the ‘simple rule’ trials in the blocked rule condition. Trial randomization happens on a by-block level. For the transfer phases, the full set of stimuli is randomized blockwise as a whole. 


## Data preparation

A sample size of 40 complete and eligible observations (after exclusion) per experimental group was preregistered, resulting in a total of 160 participations required. A naive power calculation (or estimation, rather) for a simple logistic regression assuming an odds ratio of 2, requires 34 people per group to reach a power of 80%^[Since the analysis is rather complex in addition to being conducted with bayesian modeling, a full power analysis in the classical sense was deemed beyond the scope of this thesis.]. @Chen2010 show that this assumption translates to a rather small effect, with an OR of 1.68 being equivalent to a Cohen‘s d of 0.2. Simulations by @Chen2017 show similar results and @Brysbaert2018 also recommend a sample size of about 40 people (with equally as many stimuli), albeit on a more general basis. 


### Variables, indices and aggregation

Resulting from the 2x2 factorial design described above there are two manipulated/independent variables with two levels each:

- **IV 1: Instructions** - explicitly introducting participants to look for rules and neutral language without any mentioning of rules
- **IV 2: Rule order** - blocked stimulus presentation and mixed stimulus presentation

The dependent variables are:

- **(training) Decision accuracy:** `0` or `1` - whether the presented stimulus has been correctly classified (aggregated successes _k_ of _n_ trials on subject and block level)
- **(transfer 1) Chosen category:** `Nobz` or `Grot` on the full set of stimuli; of special relevance to the research question are the nine stimuli not shown (and learned) during the training phase (see. fig. \@(ref:ch2-stimuli)), which are treated as either extrapolation (`1`) or proximation (`0`)
- **(transfer 2) Probability judgement:** `[0;100]` - integer depicting the numerical certainty of the presented stimulus belonging to either one Category.


### Data exclusion

Participants that appear to be guessing in the training phase (the probability of correct classification on a single trial being 0.5) will be excluded. The above-chance number of correct classifications needed (based on a 5% alpha level) in the last 3 training blocks (24 trials) then is 16. Additionally, should participants answer the question about any reason to not use their data in the affirmative, those participants will be excluded as well. 

While two people haven been identified in that way, after data collection and upon closer inspection, three additional participants have been identified that clearly didn't learn the category strucure. Two classified stimuli solely along one stimulus dimension only (and ignoring the second), which lead to 18 perfectly classified stimuli and 6 errors, thereby passing the threshold and one barely passed but didn't give sensible responses in the transfer phase. Figure \@ref(fig:ch2-plot-exclusions) shows the accuracy of the last three training blocks and the responses in the transfer phase. Lastly, no participant indicated to be excluded from the analysis.

(ref:ch2-plot-exclusions) Response accuracy for excluded participants on the last 3 blocks of training and respective responses of the transfer phase.

```{r ch2-plot-exclusions, fig.cap="(ref:ch2-plot-exclusions)", fig.height=2.2}
plex_train <- exclud_train %>% 
  left_join(distinct(select(exclud_trans, image, img_x, img_y)), by = "image") %>% 
  filter(block > 9) %>% 
  group_by(subj_id, img_x, img_y) %>% 
  summarise(
    p_correct = round(mean(correct) * 100, 1),
    img_x = ifelse(img_x > 2, img_x - 2, img_x),
    img_y = ifelse(img_y > 2, img_y - 2, img_y),
    .groups = "drop"
  ) %>%
  ggplot(aes(img_x, img_y, fill = p_correct)) +
    facet_wrap(~subj_id, nrow = 1) +
    geom_tile(size = .5) +
    scale_fill_viridis_c(
      guide = guide_colorbar(
        barwidth = 1,
        barheight = 3
      )
    ) +
    labs(fill = "Acc.") +
    theme_subjects +
    theme(panel.border = element_rect(color = "#3c3c3c", fill = NA),
          legend.text  = element_text(size = 6),
          legend.position = "right",
          legend.justification = c(.9, .1))

plex_trans <- ggplot(exclud_trans, aes(img_x, img_y, fill = response)) +
  facet_wrap(~subj_id, nrow = 1) +
  geom_tile(size = .5, color = "white") +
  scale_fill_manual(values = c("#ac0634", "#525252")) +
  theme_subjects +
  theme(panel.border = element_rect(color = "#525252", fill = NA),
        legend.text  = element_text(size = 6),
        legend.position = "none")

plex_train / plex_trans
```


## Analysis plan

All analyses will be conducted using R (@R4, v`r paste0(R.Version()$major, ".", R.Version()$minor, " - ", R.Version()$nickname)`). For a full list of all additionally used packages see Appendix X. As already mentioned, all raw and prepared data as well as the corresponding analysis scripts are available via the osf repository^[Again, the link to the project for convenience: [https://osf.io/gup7x/](https://osf.io/gup7x/)]. 

To investigate the hypotheses laid out in the previous chapter, several mixed-effect logistic regression models using logit-links are computed. Since the reasonably maximal random effect structure justified by the experimental setup (see @Barr2013) is not known a-priori, model complexity will be reduced to a maximal RE structure justified by the data [see @Bates2015] following these steps:

- fit model with max. RE structure
- identify posterior parameter estimates that do not conclusively differ from 0
- perform hierarchical Likelihood-Ratio-Tests; should the difference in elpd scorces calculated via leave-one-out cross validation exceed the standard deviation in differences, the model with the lower score is selected

Futhermore, all models use only weakly informative priors. @Gelman2020 recommends $\operatorname{student}(df, mean = 0, sd = 1)$ where $3 \leq df \leq 7$, since the often used Cauchy-Distribution (that is, $\operatorname{student}(1, 0, 2.5)$) has too thick tails and a strict Gaussian might be too informative in the case at hand. Finally, Bayes Factors for model comparisons are obtained by computing marginal likelihooods via bridge sampling [@Gronau2020]. Since that method requries a rather high amount of posterior samples to obtain robust bayes factors, each model will have 4 MCMC chains with 12000 samples and 2000 warm-up samples each, resulting in 40000 posterior samples drawn per model [for details, see @Schad2021].

### Model comparisons in detail

**Hypotheses 1** -- The dependent variable is whether a stimulus of the nine untrained/incomplete stimuli has been extrapolated; the independent variable is the experimental group assignment (instructions yes/no, blocked yes/no). Model comparisons for testing the hypotheses are therefore:

- **H1.1:** $M_{instructions} > M_{null}$
- **H1.2:** $M_{blocked} > M_{null}$
- **H1.3:** $M_{{instructions + blocked + interaction}} \approx M_{{instructions + blocked}} \approx M_{instructions} \approx M_{blocked} > M_{null}$

**Hypotheses 2** -- The dependent variable is the blockwise categorisation accuracy of the stimuli in the training phase and independent variable is whether or not the instructions mention rules. The models to compare are therefore:

- **H2:** $M_{instructions} > M_{null}$

In any case, $M_{null}$ denotes an intercept-only model that is otherwise identical to the models tested against.

### Inference criteria

Hypotheses are evaluated with Bayes Factors according to @Andras2014^[adjusted from Jeffreys, 1961]: $BF_{12} > 3$ constitutes moderate evidence for $M_1$ over $M_2$ (or vice versa when $BF_{12} < 1/3$) and $BF_{12} > 10$ (or $BF_{12} < 1/10$) will be interpreted as strong evidence respectively. Bayes Factors between 1/3 and 3 are treated as no meaningful evidence in favor of either model.
